{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Numbers\n",
    "\n",
    "Lexer, parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Syntactic rules| Semantic Rules |\n",
    "|:-:|:-:|\n",
    "| sec -> sec_1 `.` sec_2 | sec_1.v + sec_2.v / 2 ^ sec_2.lon |\n",
    "| sec -> sec_1 digit | sec_1.v *  2 + dig.v, sec.lon = sec_1.lon + 1 |\n",
    "| sec -> digit | sec.v = digit.v, sec.long = 1 |\n",
    "| digit| digit.v = digit.lexval[01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer, Parser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryLexer(Lexer):\n",
    "    literals = {'.'}\n",
    "    tokens = {'DIGIT'}\n",
    "\n",
    "    ignore = '\\t'\n",
    "\n",
    "    @_(r'[01]')\n",
    "    def DIGIT(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "    \n",
    "    def error(self, t):\n",
    "        print('<-'*10, \"Illegal character ' {} ' \".format(t.value[0], '->' * 10))\n",
    "        t.type = \"Illegal\"\n",
    "        t.value = t.value[0]\n",
    "        self.index +=1\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010101.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       binary\n",
       "0    01010101\n",
       "1      001010\n",
       "2           1\n",
       "3           0\n",
       "4  1010101.11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assets\\/binary.csv', dtype=object )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "0 Lexically Testing sentence: '01010101'\n",
      "--------------------------------------------------------------------------------\n",
      "Token(type='DIGIT', value=0, lineno=1, index=0)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=1)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=2)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=3)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=4)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=5)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=6)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=7)\n",
      " type = 'DIGIT', value = '1'\n",
      "--------------------------------------------------------------------------------\n",
      "1 Lexically Testing sentence: '001010'\n",
      "--------------------------------------------------------------------------------\n",
      "Token(type='DIGIT', value=0, lineno=1, index=0)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=1)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=2)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=3)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=4)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=5)\n",
      " type = 'DIGIT', value = '0'\n",
      "--------------------------------------------------------------------------------\n",
      "2 Lexically Testing sentence: '1'\n",
      "--------------------------------------------------------------------------------\n",
      "Token(type='DIGIT', value=1, lineno=1, index=0)\n",
      " type = 'DIGIT', value = '1'\n",
      "--------------------------------------------------------------------------------\n",
      "3 Lexically Testing sentence: '0'\n",
      "--------------------------------------------------------------------------------\n",
      "Token(type='DIGIT', value=0, lineno=1, index=0)\n",
      " type = 'DIGIT', value = '0'\n",
      "--------------------------------------------------------------------------------\n",
      "4 Lexically Testing sentence: '1010101.11'\n",
      "--------------------------------------------------------------------------------\n",
      "Token(type='DIGIT', value=1, lineno=1, index=0)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=1)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=2)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=3)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=4)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=0, lineno=1, index=5)\n",
      " type = 'DIGIT', value = '0'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=6)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='.', value='.', lineno=1, index=7)\n",
      " type = '.', value = '.'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=8)\n",
      " type = 'DIGIT', value = '1'\n",
      "Token(type='DIGIT', value=1, lineno=1, index=9)\n",
      " type = 'DIGIT', value = '1'\n"
     ]
    }
   ],
   "source": [
    "lexer = BinaryLexer()\n",
    "sentences = pd.read_csv('assets\\/binary.csv', dtype=object).binary\n",
    "pass_or_not = []\n",
    "all_token_pass = True \n",
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "    print('-' * 80, \"{} Lexically Testing sentence: '{}'\".format(index,\n",
    "          sentence), '-' * 80, sep='\\n')\n",
    "    for token in lexer.tokenize(sentence):\n",
    "        print(token)\n",
    "        print(\" type = '{}', value = '{}'\".format(token.type, token.value))\n",
    "        if all_token_pass and 'Illegal' in token.type:\n",
    "            all_token_pass = False\n",
    "    \n",
    "    pass_or_not.append('Pass') if all_token_pass else pass_or_not.append('FAIL')\n",
    "    all_token_pass = True\n",
    "\n",
    "data['Test'] = pass_or_not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryParser(Parser):\n",
    "    tokens = BinaryLexer.tokens\n",
    "\n",
    "    def __init__(self):\n",
    "        self.names = {}\n",
    "    \n",
    "    @_(\"num\")\n",
    "    def entrada(self, p):\n",
    "        print(\"Regla : entrada->num\")\n",
    "        print(\"El valor es \", p.num)\n",
    "    \n",
    "    @_('sec \".\" sec')\n",
    "    def num(self, p):\n",
    "        print(\"Regla: num-> sec . sec\")\n",
    "        return p.sec0[0] + p.sec1[0] / pow(2, p.sec1[1])\n",
    "    \n",
    "    @_('sec dig')\n",
    "    def sec(self, p):\n",
    "        print(\"Regla: sec -> sec dig\")\n",
    "        aux = [p.sec[0] * 2 + p.dig, p.sec[1] + 1]\n",
    "        print(aux)\n",
    "        return aux\n",
    "    \n",
    "    @_('dig')\n",
    "    def sec(self, p):\n",
    "        print(\"Regla: sec->dig\")\n",
    "        print(\"Token\", p.dig)\n",
    "        return [p.dig, 1]\n",
    "    \n",
    "    @_('DIGIT')\n",
    "    def dig(self, p):\n",
    "        print(\"Regla: dig->DIGIT\")\n",
    "        print(\"token: \", p.DIGIT)\n",
    "        return p.DIGIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regla: dig->DIGIT\n",
      "token:  1\n",
      "Regla: sec->dig\n",
      "Token 1\n",
      "Regla: dig->DIGIT\n",
      "token:  0\n",
      "Regla: sec -> sec dig\n",
      "[2, 2]\n",
      "Regla: dig->DIGIT\n",
      "token:  1\n",
      "Regla: sec -> sec dig\n",
      "[5, 3]\n",
      "Regla: dig->DIGIT\n",
      "token:  0\n",
      "Regla: sec->dig\n",
      "Token 0\n",
      "Regla: num-> sec . sec\n",
      "Regla : entrada->num\n",
      "El valor es  5.0\n"
     ]
    }
   ],
   "source": [
    "sentences = pd.read_csv('assets\\/binary.csv', dtype=object)['binary']\n",
    "lexer = BinaryLexer()\n",
    "parser = BinaryParser()\n",
    "\n",
    "# for sentence in sentences:\n",
    "parser.parse(lexer.tokenize(sentences[1]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919c7ce7a74021c6cd98257225c7c731a5c39ce25eb8800a5dd524e2eb8700bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10  ('.env': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}