{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculator Lexer - Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "| Sintactic rules | Semantics rules |\n",
    "| :-: | :-: |\n",
    "| input -> input expr ; | Escribe(expr.s) |\n",
    "| input -> $\\epsilon$ | |\n",
    "| expr -> $expr_1$ `+` sum | $expr.s = expr_1.s + sum.s$ |\n",
    "| expr -> $expr_1$ `-` sum | $expr.s = expr_1.s - sum.s$ |\n",
    "| expr -> sum |  expr.s = sum.s|\n",
    "| sum -> $sum_1 `*` fact$ | $sum.s = sum_1.s * fact.s$ |\n",
    "| sum -> $sum_1 `/` fact$ | $sum.s = sum_1.s / fact.s$ |\n",
    "| sum -> fact | sum.s = fact.s|\n",
    "| fact -> $- fact_1$ | fact.s = $- fact_1.s $|\n",
    "| fact -> NUM | fact.s = NUM.lexval |\n",
    "| fact -> `(` expr `)` | fact.s = expr.s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer, Parser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLexer(Lexer):\n",
    "    # set of tokens\n",
    "    tokens = {\n",
    "        'CNUM'\n",
    "    }\n",
    "    # set of literals\n",
    "    literals = {\n",
    "        '+', '-', '*', '/', '(', ')', ';'\n",
    "    }\n",
    "\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    \n",
    "    # special case \n",
    "    @_(r'\\d+')\n",
    "    def CNUM(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    def error(self, t):\n",
    "        print('<-'*10, \"Illegal character '{}' \".format(t.value[0], '->'*10))\n",
    "        t.type = \"Illegal\"\n",
    "        t.value = t.value[0]\n",
    "        self.index += 1\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 + 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 - 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5 * 7) + 5 - 78 / 4 + (6 - 7 ) * 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             operators\n",
       "0                               4 + 4 \n",
       "1                                5 - 5\n",
       "2  (5 * 7) + 5 - 78 / 4 + (6 - 7 ) * 2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assets\\operators.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "0 Lexically Testing sentence: '4 + 4'\n",
      "--------------------------------------------------------------------------------\n",
      " type = 'CNUM', value = '4'\n",
      " type = '+', value = '+'\n",
      " type = 'CNUM', value = '4'\n",
      "--------------------------------------------------------------------------------\n",
      "1 Lexically Testing sentence: '5 - 5'\n",
      "--------------------------------------------------------------------------------\n",
      " type = 'CNUM', value = '5'\n",
      " type = '-', value = '-'\n",
      " type = 'CNUM', value = '5'\n",
      "--------------------------------------------------------------------------------\n",
      "2 Lexically Testing sentence: '(5 * 7) + 5 - 78 / 4 + (6 - 7 ) * 2'\n",
      "--------------------------------------------------------------------------------\n",
      " type = '(', value = '('\n",
      " type = 'CNUM', value = '5'\n",
      " type = '*', value = '*'\n",
      " type = 'CNUM', value = '7'\n",
      " type = ')', value = ')'\n",
      " type = '+', value = '+'\n",
      " type = 'CNUM', value = '5'\n",
      " type = '-', value = '-'\n",
      " type = 'CNUM', value = '78'\n",
      " type = '/', value = '/'\n",
      " type = 'CNUM', value = '4'\n",
      " type = '+', value = '+'\n",
      " type = '(', value = '('\n",
      " type = 'CNUM', value = '6'\n",
      " type = '-', value = '-'\n",
      " type = 'CNUM', value = '7'\n",
      " type = ')', value = ')'\n",
      " type = '*', value = '*'\n",
      " type = 'CNUM', value = '2'\n",
      "--------------------------------------------------------------------------------\n",
      "3 Lexically Testing sentence: '5 r 8'\n",
      "--------------------------------------------------------------------------------\n",
      " type = 'CNUM', value = '5'\n",
      "<-<-<-<-<-<-<-<-<-<- Illegal character 'r' \n",
      " type = 'Illegal', value = 'r'\n",
      " type = 'CNUM', value = '8'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (4) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-67a8396fe97d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mall_token_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Test'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpass_or_not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3163\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3240\u001b[0m         \"\"\"\n\u001b[0;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3242\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3898\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3899\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3901\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    749\u001b[0m     \"\"\"\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    752\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (4) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "lexer = CalcLexer()\n",
    "sentences = pd.read_csv('assets\\operators.csv').operators\n",
    "pass_or_not = []\n",
    "all_token_pass = True\n",
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "    print('-' * 80,\"{} Lexically Testing sentence: '{}'\".format(index, sentence),'-' * 80, sep='\\n')\n",
    "    for token in lexer.tokenize(sentence):\n",
    "        print(\" type = '{}', value = '{}'\".format(token.type, token.value))\n",
    "        if all_token_pass and 'Illegal' in token.type:\n",
    "            all_token_pass = False\n",
    "    \n",
    "    pass_or_not.append('Pass') if all_token_pass else pass_or_not.append('FAIL')\n",
    "    all_token_pass = True\n",
    "\n",
    "data['Test'] = pass_or_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919c7ce7a74021c6cd98257225c7c731a5c39ce25eb8800a5dd524e2eb8700bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10  ('.env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}