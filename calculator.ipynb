{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculator Lexer - Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "| Sintactic rules | Semantics rules |\n",
    "| :-: | :-: |\n",
    "| input -> input expr ; | Escribe(expr.s) |\n",
    "| input -> $\\epsilon$ | |\n",
    "| expr -> $expr_1$ `+` sum | $expr.s = expr_1.s + sum.s$ |\n",
    "| expr -> $expr_1$ `-` sum | $expr.s = expr_1.s - sum.s$ |\n",
    "| expr -> sum |  expr.s = sum.s|\n",
    "| sum -> $sum_1 `*` fact$ | $sum.s = sum_1.s * fact.s$ |\n",
    "| sum -> $sum_1 `/` fact$ | $sum.s = sum_1.s / fact.s$ |\n",
    "| sum -> fact | sum.s = fact.s|\n",
    "| fact -> $- fact_1$ | fact.s = $- fact_1.s $|\n",
    "| fact -> NUM | fact.s = NUM.lexval |\n",
    "| fact -> `(` expr `)` | fact.s = expr.s |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sly import Lexer, Parser\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcLexer(Lexer):\n",
    "    # set of tokens\n",
    "    tokens = {\n",
    "        'CNUM'\n",
    "    }\n",
    "    # set of literals\n",
    "    literals = {\n",
    "        '+', '-', '*', '/', '(', ')', ';'\n",
    "    }\n",
    "\n",
    "    ignore = ' \\t'\n",
    "\n",
    "    \n",
    "    # special case \n",
    "    @_(r'\\d+')\n",
    "    def CNUM(self, t):\n",
    "        t.value = int(t.value)\n",
    "        return t\n",
    "\n",
    "    def error(self, t):\n",
    "        print('<-'*10, \"Illegal character '{}' \".format(t.value[0], '->'*10))\n",
    "        t.type = \"Illegal\"\n",
    "        t.value = t.value[0]\n",
    "        self.index += 1\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 + 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 - 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(5 * 7) + 5 - 78 / 4 + (6 - 7 ) * 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             operators\n",
       "0                                4 + 4\n",
       "1                                5 - 5\n",
       "2  (5 * 7) + 5 - 78 / 4 + (6 - 7 ) * 2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assets\\operators.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "0 Lexically Testing sentence: '4 + 4'\n",
      "--------------------------------------------------------------------------------\n",
      " type = 'CNUM', value = '4'\n",
      " type = '+', value = '+'\n",
      " type = 'CNUM', value = '4'\n",
      "--------------------------------------------------------------------------------\n",
      "1 Lexically Testing sentence: '5 - 5'\n",
      "--------------------------------------------------------------------------------\n",
      " type = 'CNUM', value = '5'\n",
      " type = '-', value = '-'\n",
      " type = 'CNUM', value = '5'\n",
      "--------------------------------------------------------------------------------\n",
      "2 Lexically Testing sentence: '(5 * 7) + 5 - 78 / 4 + (6 - 7 ) * 2'\n",
      "--------------------------------------------------------------------------------\n",
      " type = '(', value = '('\n",
      " type = 'CNUM', value = '5'\n",
      " type = '*', value = '*'\n",
      " type = 'CNUM', value = '7'\n",
      " type = ')', value = ')'\n",
      " type = '+', value = '+'\n",
      " type = 'CNUM', value = '5'\n",
      " type = '-', value = '-'\n",
      " type = 'CNUM', value = '78'\n",
      " type = '/', value = '/'\n",
      " type = 'CNUM', value = '4'\n",
      " type = '+', value = '+'\n",
      " type = '(', value = '('\n",
      " type = 'CNUM', value = '6'\n",
      " type = '-', value = '-'\n",
      " type = 'CNUM', value = '7'\n",
      " type = ')', value = ')'\n",
      " type = '*', value = '*'\n",
      " type = 'CNUM', value = '2'\n"
     ]
    }
   ],
   "source": [
    "lexer = CalcLexer()\n",
    "sentences = pd.read_csv('assets\\operators.csv').operators\n",
    "pass_or_not = []\n",
    "all_token_pass = True\n",
    "\n",
    "for index, sentence in enumerate(sentences):\n",
    "    print('-' * 80,\"{} Lexically Testing sentence: '{}'\".format(index, sentence),'-' * 80, sep='\\n')\n",
    "    for token in lexer.tokenize(sentence):\n",
    "        print(\" type = '{}', value = '{}'\".format(token.type, token.value))\n",
    "        if all_token_pass and 'Illegal' in token.type:\n",
    "            all_token_pass = False\n",
    "    \n",
    "    pass_or_not.append('Pass') if all_token_pass else pass_or_not.append('FAIL')\n",
    "    all_token_pass = True\n",
    "\n",
    "data['Test'] = pass_or_not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "YaccError",
     "evalue": "Unable to build grammar.\n<ipython-input-8-a9b4edcd719f>:5: Symbol ';' used, but not defined as a token or a rule\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mYaccError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a9b4edcd719f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mCalcParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCalcLexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlexval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"input expr ;\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\sly\\yacc.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(meta, clsname, bases, attributes)\u001b[0m\n\u001b[0;32m   1772\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1773\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1774\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1775\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\sly\\yacc.py\u001b[0m in \u001b[0;36m_build\u001b[1;34m(cls, definitions)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1967\u001b[0m         \u001b[1;31m# Build the underlying grammar object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1968\u001b[1;33m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__build_grammar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrules\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1970\u001b[0m         \u001b[1;31m# Build the LR tables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\repos\\c-to-assembly\\.env\\lib\\site-packages\\sly\\yacc.py\u001b[0m in \u001b[0;36m__build_grammar\u001b[1;34m(cls, rules)\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grammar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mYaccError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unable to build grammar.\\n'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mYaccError\u001b[0m: Unable to build grammar.\n<ipython-input-8-a9b4edcd719f>:5: Symbol ';' used, but not defined as a token or a rule\n"
     ]
    }
   ],
   "source": [
    "class CalcParser(Parser):\n",
    "    tokens = CalcLexer.tokens\n",
    "    lexval = {}\n",
    "\n",
    "    @_('input expr \";\"')\n",
    "    def input(self, p):\n",
    "        print(\"{} {} ;\".format(p.input, p.expr))\n",
    "    \n",
    "    @_('empty')\n",
    "    def input(self, p):\n",
    "        return ''\n",
    "\n",
    "    @_('')\n",
    "    def empty(self, p):\n",
    "        pass\n",
    "\n",
    "    @_('expr \"+\" sum')\n",
    "    def expr(self, p):\n",
    "        return p.expr + p.sum\n",
    "    @_('expr \"-\" sum')\n",
    "    def expr(self, p):\n",
    "        return p.expr - p.sum\n",
    "\n",
    "    @_(\"sum\")\n",
    "    def expr(self, p):\n",
    "        return p.sum\n",
    "    \n",
    "    @_('sum \"*\" prod')\n",
    "    def sum(self, p):\n",
    "        return p.sum * p.prod\n",
    "    \n",
    "    @_('sum \"/\" prod')\n",
    "    def sum(self, p):\n",
    "        if p.prod != 0:\n",
    "            return p\n",
    "        raise ZeroDivisionError\n",
    "    \n",
    "    @_('prod')\n",
    "    def sum(self, p):\n",
    "        return p.prod\n",
    "    \n",
    "    @_(' \"-\" prod')\n",
    "    def prod(self, p ):\n",
    "        return - p.prod\n",
    "    \n",
    "    @_('CNUM')\n",
    "    def prod(self, p):\n",
    "        return p.CNUM\n",
    "    \n",
    "    @_(' \"(\" expr \")\" ')\n",
    "    def prod(self, p):\n",
    "        return p.expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919c7ce7a74021c6cd98257225c7c731a5c39ce25eb8800a5dd524e2eb8700bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10  ('.env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}